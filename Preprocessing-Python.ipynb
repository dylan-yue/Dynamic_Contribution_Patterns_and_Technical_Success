{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling time series\n",
    "import json\n",
    "import codecs\n",
    "import sys\n",
    "import logging\n",
    "import pandas\n",
    "import pretty_errors\n",
    "from dateutil.parser import parse\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "\n",
    "def loadJson(filename):\n",
    "    logging.info('Loading ' + filename)\n",
    "    input = codecs.open(filename, 'r', 'utf8')\n",
    "    result = json.loads(input.read())\n",
    "    input.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def printJson(data, filename):\n",
    "    logging.info('Printing ' + filename)\n",
    "    output = codecs.open(filename, 'w', 'utf8')\n",
    "    output.write(json.dumps(data, ensure_ascii=False))\n",
    "    output.close()\n",
    "    return\n",
    "\n",
    "\n",
    "class TimeSeries:\n",
    "    def __init__(self, project: str, behavior: str):\n",
    "        self.project = project\n",
    "        logging.info('Project: %s', project)\n",
    "        self.result = {}\n",
    "        self.commits = {}\n",
    "        self.sorted_commits = []\n",
    "        self.developers = {}\n",
    "        self.behavior = behavior\n",
    "\n",
    "        # load commits from file\n",
    "        all_commits = loadJson('Data/commits/' + project +\n",
    "                               '_commit_alias.json')\n",
    "        logging.info('%s - Total commits: %s', project, len(all_commits))\n",
    "\n",
    "        for commit in all_commits:\n",
    "            self.commits[commit['sha']] = commit\n",
    "            self.sorted_commits.append((parse(commit['date']), commit['sha']))\n",
    "            author = commit['author']\n",
    "            if author not in self.developers:\n",
    "                self.developers[author] = []\n",
    "            self.developers[author].append(\n",
    "                (parse(commit['date']), commit['sha']))\n",
    "\n",
    "        self.sorted_commits.sort()\n",
    "        logging.info('%s - Finish loading data')\n",
    "        return\n",
    "\n",
    "    def GenerateTSForDeveloper(self, developer: str, behavior: str, n: int):\n",
    "        logging.info('%s - Developer: %s', self.project, developer)\n",
    "        # sort developer's commits by date\n",
    "        self.developers[developer].sort()\n",
    "        # get trace data by behavior\n",
    "        trace = []\n",
    "        for dt, sha in self.developers[developer]:\n",
    "            commit = self.commits[sha]\n",
    "            count = 0\n",
    "            for f in commit['modification']:\n",
    "                if f['change_type'] == behavior:\n",
    "                    count = count + 1\n",
    "            trace.append((dt, count))\n",
    "\n",
    "        first, ts = self.__generate_ts(trace, n)\n",
    "        return first, ts\n",
    "\n",
    "    def GenerateForAll(self, n: int):\n",
    "        logging.info('%s - Generating time series', self.project)\n",
    "        for developer in self.developers:\n",
    "            first, ts = self.GenerateTSForDeveloper(developer, self.behavior,\n",
    "                                                    n)\n",
    "            if ts:\n",
    "                self.result[developer + ' - ' + str(first)] = ts\n",
    "        return\n",
    "\n",
    "    def OutputTS(self):\n",
    "        logging.info('%s - Output time series to file', self.project)\n",
    "        # output to json\n",
    "        printJson(self.result,\n",
    "                  'Data/ts/' + self.project + '_' + self.behavior + '_ts.json')\n",
    "\n",
    "        # output to csv\n",
    "        self.__to_csv()\n",
    "        return\n",
    "\n",
    "    def __generate_ts(self, trace: list, n: int):\n",
    "        terminated = parse('2020-05-31 23:59:59-12:00')\n",
    "        # sort the trace\n",
    "        trace.sort()\n",
    "        # check if there is enough data\n",
    "        first_dt = trace[0][0]\n",
    "        if (terminated - first_dt).days >= n:\n",
    "            # initialize the time series\n",
    "            result = [\n",
    "                0,\n",
    "            ] * n\n",
    "            for dt, count in trace:\n",
    "                index = (dt - first_dt).days\n",
    "                if index < n:\n",
    "                    result[index] = result[index] + count\n",
    "            return first_dt, result\n",
    "        else:\n",
    "            logging.error('No enough data to generate time series')\n",
    "            return first_dt, None\n",
    "\n",
    "    def __to_csv(self):\n",
    "        # transfor to DataFrame\n",
    "        temp = []\n",
    "        for developer in self.result:\n",
    "            for i in range(len(self.result[developer])):\n",
    "                temp.append([\n",
    "                    self.project + ' - ' + developer, i,\n",
    "                    self.result[developer][i]\n",
    "                ])\n",
    "\n",
    "        result = pandas.DataFrame(data=temp,\n",
    "                                  columns=['developer', 'day', self.behavior])\n",
    "        # output to csv file\n",
    "        result.to_csv(path_or_buf='Data/ts/' + self.project + '_' +\n",
    "                      self.behavior + '_ts.csv',\n",
    "                      header=True,\n",
    "                      index=False)\n",
    "        return\n",
    "\n",
    "\n",
    "projects = loadJson('Data/Target_projects.json')\n",
    "for project in projects:\n",
    "    ts = TimeSeries(project=project['name'], behavior='MODIFY')\n",
    "    ts.GenerateForAll(n=180)\n",
    "    ts.OutputTS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time series features\n",
    "import sys\n",
    "import pandas\n",
    "import logging\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction.feature_calculators import *\n",
    "from tsfresh.feature_extraction import *\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "# input target ecosystem\n",
    "eco = sys.argv[1]\n",
    "\n",
    "# load time series\n",
    "data = pandas.read_csv('Data/ts/ecosystem_' + eco + '_MODIFY_ts.csv', header=0)\n",
    "logging.info('Ecosystem: %s', eco)\n",
    "logging.info(data.shape)\n",
    "\n",
    "# Extract ts features\n",
    "settings = ComprehensiveFCParameters()\n",
    "logging.info('Extracting features')\n",
    "result = extract_features(data,\n",
    "                          column_id='developer',\n",
    "                          column_sort='day',\n",
    "                          default_fc_parameters=settings,\n",
    "                          n_jobs=8)\n",
    "logging.info('Output result to file')\n",
    "result.to_csv(path_or_buf='Data/ts_features/' + eco + 'MODIFY_features.csv',\n",
    "              header=True,\n",
    "              index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract ts features for documentation contribution\n",
    "# 35 newcomers who have both code and doc contribution\n",
    "import pandas\n",
    "from tsfresh.feature_extraction import *\n",
    "from tsfresh import extract_features\n",
    "\n",
    "LEN = 180\n",
    "\n",
    "#Load 35 newcomers\n",
    "raw_newcomers = pandas.read_excel('Data/Newcomers with both contribution.xlsx',\n",
    "                                  header=0,\n",
    "                                  engine='openpyxl')\n",
    "newcomers = []\n",
    "for index, row in raw_newcomers.iterrows():\n",
    "    newcomers.append((row['project'], row['author']))\n",
    "print(len(newcomers))\n",
    "\n",
    "#Load raw data\n",
    "raw = pandas.read_csv('Data/doc/Doc_contribution_timeseries.csv', header=0)\n",
    "\n",
    "#Processing format\n",
    "data = []\n",
    "for index, row in raw.iterrows():\n",
    "    if (row['project'], row['author_login']) in newcomers:\n",
    "        id = row['project'] + ' - ' + row['author_login']\n",
    "        for i in range(LEN):\n",
    "            data.append({'id': id, 'day': i, 'Doc': row[str(i)]})\n",
    "data = pandas.DataFrame(data)\n",
    "\n",
    "#Extract features\n",
    "settings = ComprehensiveFCParameters()\n",
    "result = extract_features(data,\n",
    "                          column_id='id',\n",
    "                          column_sort='day',\n",
    "                          default_fc_parameters=settings,\n",
    "                          n_jobs=8)\n",
    "\n",
    "result.to_csv(path_or_buf='Data/doc/doc_ts_filtered_features_35.csv',\n",
    "              header=True,\n",
    "              index=True)\n",
    "summary = result.describe()\n",
    "summary.to_csv('Data/doc/doc_ts_filtered_features_summary_35.csv',\n",
    "               header=True,\n",
    "               index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling evidence for case study\n",
    "import json\n",
    "import codecs\n",
    "import pandas\n",
    "import datetime\n",
    "\n",
    "\n",
    "def loadJson(filename: str):\n",
    "    # print('Loading ' + filename)\n",
    "    result = []\n",
    "    input = codecs.open(filename, 'r', 'utf8')\n",
    "    result = json.loads(input.read())\n",
    "    input.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "#Load targeted projects\n",
    "projects = loadJson('Data/Target_project_doc.json')\n",
    "\n",
    "#Load commit messages\n",
    "commit_messages = {}\n",
    "for project in projects:\n",
    "    commit_messages[project['name']] = {}\n",
    "    temp = loadJson('Data/commit_info/' + project['name'] +\n",
    "                    '_commit_contributor_0601.json')\n",
    "    for item in temp:\n",
    "        sha = item['sha']\n",
    "        if 'author_login' in item:\n",
    "            login = item['author_login']\n",
    "        else:\n",
    "            login = item['author']['name']\n",
    "        msg = item['message']\n",
    "        t = datetime.datetime.strptime(item['author']['date'],\n",
    "                                       '%Y-%m-%dT%H:%M:%SZ')\n",
    "        commit_messages[project['name']][sha] = (msg, t)\n",
    "\n",
    "#Load newcomers with both types of contributions\n",
    "raw_newcomers = pandas.read_excel('Data/Newcomers with both contribution.xlsx',\n",
    "                                  header=0,\n",
    "                                  engine='openpyxl')\n",
    "newcomers = {}\n",
    "for index, row in raw_newcomers.iterrows():\n",
    "    if row['project'] not in newcomers:\n",
    "        newcomers[row['project']] = []\n",
    "    newcomers[row['project']].append(row['author'])\n",
    "\n",
    "#Load doc commits\n",
    "raw_doc = pandas.read_csv('Data/doc/Doc_contribution_commits_targeted.csv',\n",
    "                          header=0)\n",
    "\n",
    "result = []\n",
    "for project in newcomers:\n",
    "    for author in newcomers[project]:\n",
    "        #Get list of doc commits\n",
    "        doc_list = raw_doc[(raw_doc['project'] == project)\n",
    "                           & (raw_doc['author_login'] == author)]['sha']\n",
    "        doc_list = list(set(doc_list))\n",
    "\n",
    "        #Get list of code commits\n",
    "        raw_code = loadJson('Data/commits/' + project + '_commit_alias.json')\n",
    "        code_list = []\n",
    "        for item in raw_code:\n",
    "            if item['author'] == author:\n",
    "                code_list.append(item['sha'])\n",
    "        #Merge two lists\n",
    "        commits = doc_list + code_list\n",
    "        commits = list(set(commits))\n",
    "\n",
    "        #Formatting\n",
    "        for c in commits:\n",
    "            temp = {\n",
    "                'project': project,\n",
    "                'author': author,\n",
    "                'sha': c,\n",
    "                'date': None,\n",
    "                'msg': None,\n",
    "                'is_code': False,\n",
    "                'is_doc': False\n",
    "            }\n",
    "            if c in commit_messages[project]:\n",
    "                temp['date'] = commit_messages[project][c][1]\n",
    "                temp['msg'] = commit_messages[project][c][0]\n",
    "            if c in doc_list:\n",
    "                temp['is_doc'] = True\n",
    "            if c in code_list:\n",
    "                temp['is_code'] = True\n",
    "            result.append(temp)\n",
    "result = pandas.DataFrame(result)\n",
    "result.to_csv('Data/Newcomers_commit_msg_list.csv', header=True, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9253a008b17140f09993078200900285"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
